# Threads and Connections in backend applications

Lets looks at some **definations** before diving into architecture üë®üèª‚Äçüíª

## Listener

When a program wants to communicate over the internet, it opens a "socket", which is like a door that others can knock to talk to program.

## Accepter

When someone knock the door(socket), the program needs to decide whether to let them in or not.

## Reader

Once the connection build, data starts flowing through it. But this data isn't neatly packaged like email its more like a continuous stream of bytes. The reader's job is to make sence of this stream by organising it into meaningful pieces, like understanding where one messages end and another starts.

## TCP (Transmission Communication Protocol)

TCP is underlying protocol that ensures that data gets form one place to another reliably, it doesn't care about the structure of the data itself. Its like a delivery truck that transports packacges. The reader's job is to unpack the packages and make sence of them, like understanding the individual requests being sent on the internet.

# Architecture pattern

## Single Threaded Architecture

In this architecture, backend application handles all the aspects of connection management, including listening for incoming connections, accepting them, and processing the data streams. This approach is simple and straightforward, but this may struggle to handle high loads efficiently due to its single threaded nature.

**Example:** Node.js operates a single-threaded event loop model where a single thread manages all incoming requests and responses.

## Multiple Threads Single Acceptor Architecture

The Multiple Threads Single Acceptor Architecture is a desigh pattern used in building performant backend applications that leverage multi-threading to take advantage of all CPU cores. In this architecture, a single listener thread is responsible for accepting connections, but each accepted connection is handed over to a separate worker thread for processing.

### How this architecture works

1. Single Listener Thread:
   There is only one listener thread responsible for acceptiong incoming connection requests. This thread binds to a specific IP address and port, wating for clients to establish connections.

2. Connection Acceptance:
   When a clients initiates a connection request, the listener thread accepts it. However, instead of prcessing the data itself, the listener thread delegates the connection to another worker thread.

3. Worker threads:
   Each accepted connection is handed over to a separate worker thread for processing. Thses worker threads are responsible for reading data from the connection, performing any necessary computations or operations, and generating responses.

4. Maximizing CPU Utilization:
   The number of worker threads can be configured based on the number of CPU cores available. A common rule-to-thumb is to have one thread per CPU core. This ensures that each CPU core is fully utilized, maximizing overall performance.

5. Shared Connections:
   To prevent excessive thread creation and memory consumption, multiple connections may be shared among worker threads. This means that each thread is responsible for processing multiple connections concurrently.

6. Limitaitions:

- If the listener thread cannot accept connections fast enough, clients may experience high latency
- Additionally, there may be issues with load balancing among work threads. Some threads may end up processing more requests than others, leading to uneven distribution of workload.

**Overall** the Multiple Threads Single Acceptor Architecture offers a balance between performance and complexity, allowing backend applications to efficiently utilize multi-core CPUs while managing incoming connections effectively.

## Multiple Threads Multiple Acceptors Architecture

In the Multiple Threads Multiple Acceptors Architecture, a single listener thread is responsible for creating the socket and placing it in shared memory accessible to other threads. Multiple worker threads are then created, each of which calls accept on the shared socket object to accept incoming connections. In this model, each worker thread takes on the dual role of acceptor and reader, handling both the acceptance of connections and the processing of data.

### How this architecture works

1. Shared Socket Object:
   This listtener thread creates a sockets and places it in shares memory where other threds can access it. This allows multiples threads to accept connections form the same socket.

2. Worker Threads:
   Each worker is responsible for calling accept on the shared socket object to accept incoming connections. Once a connection is accepted, the thread takes ownship of that connection and becomes responsible for processing data from it.

3. Dispersed Connection Management:
   By dispersing the responsibility of connection management to local threads, this architecture aims to improve concurrency and performance. Each thread handles its own set of connections independently.

4. Limitaions:

- All threads compete to accrpt connections on the single shared socket object. This competition leading to serilization of threads and potential blocking, which can result in high latencies.
- Some threads may end up processing more requests than others, leading to uneven distribution of workload.

**Example:** NGINX, a widely used web server and reverse proxy server, used this architecture by default prior to version 1.9.1. In NGINX, multiple worker processes are created, each of which handles its own set of connections independently, improving concurrency and performance.

## Multiple Threads with Message-based Load Balancing Architecture

In this special architecture used by systems like <a href="/Handbook/RAMCloud.md">RAMCloud</a>, the way connections and work are handled is a bit different. Instead of just passing connections to different workers, there's a special "listener" who not only listens for connections but also reads and sorts the messages that come through. Once the messages are all sorted out, they're given to different worker buddies to deal with.

Now, this setup is pretty smart because it makes sure that no worker gets too overloaded with work while others sit idle. It's like making sure everyone gets a fair share of the chores to do.

But there's a bit of a problem with this setup too. Because the listener is doing a lot of work by reading and sorting all the messages, it can sometimes get overwhelmed. Imagine trying to juggle too many balls at once ‚Äì it can get pretty tricky! This can slow things down a bit, especially when lots of messages are coming in at the same time.

So while this architecture is great at making sure everyone gets a fair share of work, sometimes the listener can become a bit of a bottleneck, slowing things down. But with some clever tricks, like using special ways of handling messages, we can make things run smoother and keep everyone happy.